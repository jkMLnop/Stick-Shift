#!/bin/sh

#NOTE this was performed on a ubuntu 18.04 LTS OS, t2 micro, with autogenerated
#     public IP and in same VPC as all pipeline components to be automated

# install any missing python3 resources on actual machine
sudo apt-get install python3-setuptools
sudo easy_install3 pip

# get updates
sudo apt update

sudo apt -y install python3-pip

# run to check that you are at latest version of pip (19.1.1):
sudo pip3 install --upgrade pip

# "pip3 --version" and "pip --version" at this point should both tell you python 3.5 pip 19.1.1
# #NOTE from here on out pip points to pip3

# install, name and activate virtual environment for airflow to run on
pip install --user virtualenv
#virtualenv ~/venv

virtualenv -p /usr/bin/python3.5 ~/venv #set python 3.5 to be default for the virtual environment!
source ~/venv/bin/activate

# start loading up virtual environment with everything we need for airflow to run
sudo apt update

pip install flask
pip install psycopg2-binary

mkdir flaskexample
mkdir flaskexample/static
mkdir flaskexample/templates
mkdir tmp

pip install sqlalchemy
pip install sqlalchemy_utils
pip install pandas
